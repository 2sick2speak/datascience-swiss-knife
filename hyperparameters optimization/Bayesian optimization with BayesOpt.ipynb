{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/voting outcomes/train2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract target vector and drop useless data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train['Party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Party','USER_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.fillna('NoData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert YOB to age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_age(age):\n",
    "    if age != 'NoData':\n",
    "        return 2016 - age\n",
    "    else:\n",
    "        return 'NoData'\n",
    "\n",
    "train['YOB'] = train['YOB'].apply(convert_to_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggeregate age to age groups (numerical -> ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_borders = [18, 27, 35, 50, 65, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_border(age, borders):\n",
    "    i = 0\n",
    "    while i < len(borders):\n",
    "        if age >= borders[i]:\n",
    "            i += 1\n",
    "        else:\n",
    "            return str(i)\n",
    "    \n",
    "    return str(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = train['YOB']!='NoData'\n",
    "\n",
    "train['YOB'][mask] = train['YOB'][mask].apply(return_border, borders = age_borders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_binary = lb.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple xgboost for classification:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.Series(target_binary)\n",
    "skf = StratifiedKFold(y.values, n_folds=10, random_state=1488)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross validated xgboost \n",
    "\n",
    "def xgboostcv(eta,\n",
    "              subsample,\n",
    "              colsample_bytree,\n",
    "              min_child_weight,\n",
    "              max_depth,\n",
    "              seed = 1488,\n",
    "              verbose = False):\n",
    "    \n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary:logistic\"\n",
    "    params[\"eta\"] = eta\n",
    "    params[\"min_child_weight\"] = min_child_weight\n",
    "    params[\"subsample\"] = subsample\n",
    "    params[\"colsample_bytree\"] = colsample_bytree\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = int(max_depth)\n",
    "    params[\"eval_metric\"] = \"error\"\n",
    "    params['seed'] = seed\n",
    "    results = []\n",
    "    \n",
    "    for (i, (train_index, test_index)) in enumerate(skf):\n",
    "        xg_train = xgb.DMatrix(train.ix[train_index], label=y.ix[train_index] , missing=np.nan)\n",
    "        xg_test = xgb.DMatrix(train.ix[test_index], label=y.ix[test_index], missing=np.nan)\n",
    "        watchlist = [(xg_train,'train'), (xg_test, 'test')]\n",
    "        bst = xgb.train(params, xg_train, num_round, watchlist, early_stopping_rounds=30, verbose_eval=False)\n",
    "        if verbose:\n",
    "            print 'Accuracy on fold {num}: {acc}'.format(num=i, acc=(1 - bst.best_score))\n",
    "        results.append(bst.best_score)\n",
    "\n",
    "    # bayes_opt use maximize() method, so we invert our target metric \n",
    "    # to convert task from minimization to maximization \n",
    "    return -np.mean(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually selected params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on fold 0: 0.639785\n",
      "Accuracy on fold 1: 0.660682\n",
      "Accuracy on fold 2: 0.64632\n",
      "Accuracy on fold 3: 0.637343\n",
      "Accuracy on fold 4: 0.640934\n",
      "Accuracy on fold 5: 0.639138\n",
      "Accuracy on fold 6: 0.630162\n",
      "Accuracy on fold 7: 0.636691\n",
      "Accuracy on fold 8: 0.622302\n",
      "Accuracy on fold 9: 0.564748\n"
     ]
    }
   ],
   "source": [
    "avg_acc = xgboostcv(eta=0.01, \n",
    "                    subsample=0.9, \n",
    "                    colsample_bytree=0.8, \n",
    "                    min_child_weight=1, \n",
    "                    max_depth=6, \n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6318105\n"
     ]
    }
   ],
   "source": [
    "print \"Average accuracy: {acc}\".format(acc = (1 + avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_space = {'eta': (0.01, 0.1),\n",
    "                'subsample': (0.6, 0.95),\n",
    "                'min_child_weight': (1, 4),\n",
    "                'colsample_bytree': (0.6, 0.95),\n",
    "                'max_depth': (3, 12)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run N_ITER number of iterations to find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_ITER = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 00m21s | \u001b[35m  -0.36693\u001b[0m | \u001b[32m            0.6431\u001b[0m | \u001b[32m   0.0199\u001b[0m | \u001b[32m     8.5418\u001b[0m | \u001b[32m            2.0275\u001b[0m | \u001b[32m     0.9061\u001b[0m | \n",
      "    2 | 00m09s | \u001b[35m  -0.36011\u001b[0m | \u001b[32m            0.7958\u001b[0m | \u001b[32m   0.0748\u001b[0m | \u001b[32m     4.7933\u001b[0m | \u001b[32m            1.9264\u001b[0m | \u001b[32m     0.9408\u001b[0m | \n",
      "    3 | 00m11s |   -0.36082 |             0.6281 |    0.0725 |      5.1527 |             1.8710 |      0.8455 | \n",
      "    4 | 00m16s |   -0.36316 |             0.6935 |    0.0596 |      6.6169 |             1.2981 |      0.8284 | \n",
      "    5 | 00m07s |   -0.36532 |             0.7410 |    0.0767 |      3.2957 |             2.4387 |      0.9264 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |   max_depth |   min_child_weight |   subsample | \n",
      "    6 | 00m19s |   -0.36675 |             0.7430 |    0.0902 |      6.9054 |             1.8312 |      0.8898 | \n",
      "    7 | 00m10s |   -0.36388 |             0.7677 |    0.0744 |      4.8517 |             1.9170 |      0.9249 | \n",
      "    8 | 00m35s |   -0.36819 |             0.9081 |    0.0190 |     10.2295 |             3.8950 |      0.8843 | \n",
      "    9 | 00m15s |   -0.36370 |             0.9181 |    0.0755 |      5.6118 |             3.2624 |      0.9145 | \n",
      "   10 | 00m15s | \u001b[35m  -0.35885\u001b[0m | \u001b[32m            0.6784\u001b[0m | \u001b[32m   0.0734\u001b[0m | \u001b[32m     5.1572\u001b[0m | \u001b[32m            1.8694\u001b[0m | \u001b[32m     0.8641\u001b[0m | \n",
      "   11 | 00m14s |   -0.36496 |             0.9181 |    0.0307 |      5.0822 |             2.5066 |      0.8170 | \n",
      "   12 | 00m12s |   -0.36190 |             0.6937 |    0.0785 |      5.1479 |             1.8814 |      0.8720 | \n",
      "   13 | 00m14s |   -0.36226 |             0.6898 |    0.0715 |      5.1633 |             1.8701 |      0.8701 | \n",
      "   14 | 00m11s |   -0.36280 |             0.6039 |    0.0228 |      4.7565 |             1.7015 |      0.8978 | \n",
      "   15 | 00m17s |   -0.36226 |             0.6912 |    0.0724 |      6.6043 |             1.3002 |      0.7822 | \n",
      "   16 | 00m15s |   -0.35992 |             0.7676 |    0.0523 |      4.7470 |             1.9199 |      0.7915 | \n",
      "   17 | 00m16s |   -0.35938 |             0.6746 |    0.0797 |      5.1572 |             1.8657 |      0.8585 | \n",
      "   18 | 00m12s |   -0.36657 |             0.8405 |    0.0344 |      4.7864 |             1.0722 |      0.6971 | \n",
      "   19 | 00m14s |   -0.36406 |             0.7262 |    0.0449 |      4.7493 |             1.8666 |      0.8180 | \n",
      "   20 | 00m18s |   -0.35974 |             0.6744 |    0.0671 |      5.1449 |             1.8724 |      0.8672 | \n",
      "   21 | 00m17s |   -0.36100 |             0.6778 |    0.0783 |      5.4047 |             1.8878 |      0.8818 | \n",
      "   22 | 00m15s |   -0.36100 |             0.6781 |    0.0771 |      5.0099 |             1.9161 |      0.8684 | \n",
      "   23 | 00m11s |   -0.36083 |             0.6779 |    0.0730 |      5.0444 |             1.8527 |      0.8519 | \n",
      "   24 | 00m13s | \u001b[35m  -0.35705\u001b[0m | \u001b[32m            0.6774\u001b[0m | \u001b[32m   0.0760\u001b[0m | \u001b[32m     5.2032\u001b[0m | \u001b[32m            1.7779\u001b[0m | \u001b[32m     0.8719\u001b[0m | \n",
      "   25 | 00m10s |   -0.36298 |             0.7716 |    0.0543 |      4.9024 |             2.1413 |      0.7849 | \n",
      "   26 | 00m12s |   -0.36118 |             0.6300 |    0.0726 |      5.3473 |             1.5868 |      0.8479 | \n",
      "   27 | 00m09s |   -0.36406 |             0.8048 |    0.0765 |      4.7080 |             1.7808 |      0.9158 | \n",
      "   28 | 00m13s | \u001b[35m  -0.35633\u001b[0m | \u001b[32m            0.6219\u001b[0m | \u001b[32m   0.0815\u001b[0m | \u001b[32m     5.8892\u001b[0m | \u001b[32m            1.7287\u001b[0m | \u001b[32m     0.9328\u001b[0m | \n",
      "   29 | 00m13s |   -0.36334 |             0.6769 |    0.0776 |      5.1859 |             1.6480 |      0.8878 | \n",
      "   30 | 00m11s |   -0.35813 |             0.7725 |    0.0717 |      4.9159 |             1.8534 |      0.7946 | \n",
      "   31 | 00m14s |   -0.36173 |             0.6756 |    0.0779 |      5.6457 |             1.7906 |      0.8666 | \n",
      "   32 | 00m11s |   -0.35759 |             0.6225 |    0.0808 |      5.8305 |             1.7213 |      0.9255 | \n",
      "   33 | 00m12s |   -0.36047 |             0.7875 |    0.0773 |      4.7827 |             1.5593 |      0.7327 | \n",
      "   34 | 00m10s |   -0.35723 |             0.6219 |    0.0777 |      5.9701 |             1.7377 |      0.9368 | \n",
      "   35 | 00m10s |   -0.36119 |             0.7732 |    0.0646 |      4.8051 |             1.8089 |      0.7833 | \n",
      "   36 | 00m11s |   -0.35777 |             0.7876 |    0.0916 |      4.8243 |             1.4142 |      0.7339 | \n",
      "   37 | 00m14s |   -0.35759 |             0.7688 |    0.0681 |      4.9064 |             1.8939 |      0.8070 | \n",
      "   38 | 00m16s | \u001b[35m  -0.35616\u001b[0m | \u001b[32m            0.7881\u001b[0m | \u001b[32m   0.0921\u001b[0m | \u001b[32m     5.0621\u001b[0m | \u001b[32m            1.4488\u001b[0m | \u001b[32m     0.7341\u001b[0m | \n",
      "   39 | 00m11s |   -0.35939 |             0.6268 |    0.0831 |      4.9891 |             1.5313 |      0.8163 | \n",
      "   40 | 00m14s |   -0.35939 |             0.7874 |    0.0962 |      5.0399 |             1.4656 |      0.7408 | \n",
      "   41 | 00m12s |   -0.36100 |             0.6268 |    0.0724 |      5.2020 |             1.1300 |      0.8532 | \n",
      "   42 | 00m13s |   -0.35687 |             0.6100 |    0.0922 |      5.9610 |             1.0573 |      0.9176 | \n",
      "   43 | 00m12s |   -0.35975 |             0.7686 |    0.0685 |      4.7603 |             1.6563 |      0.8019 | \n",
      "   44 | 00m16s |   -0.36154 |             0.7887 |    0.0913 |      5.0479 |             1.4032 |      0.7288 | \n",
      "   45 | 00m11s |   -0.35921 |             0.6412 |    0.0571 |      4.5608 |             1.5416 |      0.6893 | \n",
      "   46 | 00m12s |   -0.36442 |             0.6193 |    0.0118 |      4.7399 |             1.4951 |      0.8444 | \n",
      "   47 | 00m12s |   -0.36083 |             0.7759 |    0.0722 |      4.7997 |             1.6182 |      0.7744 | \n",
      "   48 | 00m12s |   -0.36226 |             0.6307 |    0.0892 |      5.6066 |             1.9022 |      0.8495 | \n",
      "   49 | 00m14s |   -0.35741 |             0.6764 |    0.0679 |      5.3187 |             1.5827 |      0.6233 | \n",
      "   50 | 00m10s |   -0.36190 |             0.6351 |    0.0697 |      4.7643 |             1.5384 |      0.7460 | \n",
      "   51 | 00m14s |   -0.35831 |             0.6275 |    0.0789 |      5.7745 |             1.8317 |      0.7728 | \n",
      "   52 | 00m13s |   -0.35921 |             0.7721 |    0.0641 |      4.8554 |             1.8787 |      0.7851 | \n",
      "   53 | 00m11s |   -0.36460 |             0.7879 |    0.0674 |      3.6373 |             1.6817 |      0.7757 | \n",
      "   54 | 00m12s |   -0.36585 |             0.6060 |    0.0238 |      5.0571 |             1.0997 |      0.9222 | \n",
      "   55 | 00m14s |   -0.36154 |             0.7676 |    0.0760 |      4.9782 |             1.8724 |      0.8173 | \n",
      "-----------------------------------------------------\n",
      "Final Results\n",
      "Average accuracy: 0.643844\n"
     ]
    }
   ],
   "source": [
    "xgbBO = BayesianOptimization(xgboostcv, search_space)\n",
    "\n",
    "xgbBO.maximize(n_iter=N_ITER)\n",
    "\n",
    "print('-'*53)\n",
    "print('Final Results')\n",
    "print('Average accuracy: %f' % (1+xgbBO.res['max']['max_val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7881412413034331,\n",
       " 'eta': 0.092129799923265018,\n",
       " 'max_depth': 5.0621102463558092,\n",
       " 'min_child_weight': 1.4488271403601218,\n",
       " 'subsample': 0.73410419114918546}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimal params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_params = xgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on fold 0: 0.646953\n",
      "Accuracy on fold 1: 0.655296\n",
      "Accuracy on fold 2: 0.67325\n",
      "Accuracy on fold 3: 0.644524\n",
      "Accuracy on fold 4: 0.642729\n",
      "Accuracy on fold 5: 0.64991\n",
      "Accuracy on fold 6: 0.669659\n",
      "Accuracy on fold 7: 0.631295\n",
      "Accuracy on fold 8: 0.660072\n",
      "Accuracy on fold 9: 0.564748\n"
     ]
    }
   ],
   "source": [
    "avg_acc = xgboostcv(eta=optimal_params['eta'], \n",
    "                    subsample=optimal_params['subsample'], \n",
    "                    colsample_bytree=optimal_params['colsample_bytree'], \n",
    "                    min_child_weight=optimal_params['min_child_weight'], \n",
    "                    max_depth=optimal_params['max_depth'], \n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with BayesOpt params: 0.6438436\n"
     ]
    }
   ],
   "source": [
    "print \"Average accuracy with BayesOpt params: {acc}\".format(acc = (1 + avg_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
